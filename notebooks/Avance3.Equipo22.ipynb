{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Detección de barras en galaxias - Modelo \"Baseline\"\n",
    "## Proyecto integrador MNA\n",
    "\n",
    "### Integrantes\n",
    "- Jonathan Jesús Marmolejo Hernández - A01795195\n",
    "- Isaid Posadas Oropeza - A01795015\n",
    "- Luis Daniel Ortega Muñoz - A01795197"
   ],
   "id": "83c1172cf0612932"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Uncomment this if running in Google Colab. It will install the bargal package from GitHub.\n",
    "# !pip install git+https://github.com/ludanortmun/itesm-mna-barred-galaxies.git"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Importando librerías",
   "id": "376059bc1092e695"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T05:55:47.214041Z",
     "start_time": "2025-05-15T05:55:43.393877Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from bargal.dataset.load import load_dataset"
   ],
   "id": "4dff0f7f031c36a2",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T05:55:47.982903Z",
     "start_time": "2025-05-15T05:55:47.967128Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ],
   "id": "7d0725ae9d82b13f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preparando el conjunto de datos",
   "id": "a2fa3000020d032"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "El primer paso consiste en cargar nuestro conjunto de datos y dividirlo en conjunto de entrenamiento, validación y prueba.",
   "id": "66b99aa26d93734f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T05:56:28.594097Z",
     "start_time": "2025-05-15T05:56:28.549651Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset_path = '../data/dataset.csv'\n",
    "\n",
    "df = load_dataset(dataset_path)\n",
    "\n",
    "df.info()\n",
    "\n",
    "# TODO: Do an actual train-valid-test split\n",
    "train_df = df.iloc[:200]\n",
    "valid_df = df.iloc[200:250]\n",
    "test_df = df.iloc[250:300]"
   ],
   "id": "676bd3ff6a6b1a0f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10126 entries, 0 to 10125\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   name    10126 non-null  object \n",
      " 1   objra   10126 non-null  float64\n",
      " 2   objdec  10126 non-null  float64\n",
      " 3   Bars    10126 non-null  float64\n",
      "dtypes: float64(3), object(1)\n",
      "memory usage: 316.6+ KB\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Ahora creamos nuestra clase para representar el conjunto de datos, heredando de Dataset de PyTorch. El dataset a utilizar para nuestra red neuronal consiste en imágenes de galaxias y su respectiva etiqueta, que indica si la galaxia tiene o no una barra.\n",
    "\n",
    "La etiqueta es un tensor de tamaño 1, donde 1 indica que la galaxia tiene una barra y 0 indica que no. Sin embargo, el conjunto de datos original no tiene etiquetas binarias, sino múltiples categorías indicando el tipo de barra que tiene la galaxia. Por lo tanto, convertimos cualquier etiqueta que represente la presencia de una barra (independientemente de sus características) a 1 y cualquier etiqueta que represente la ausencia de una barra a 0; de forma similar a como se realizó en el entregable [Avance1.Equipo22.ipynb](https://github.com/ludanortmun/itesm-mna-barred-galaxies/tree/main/notebooks/Avance1.Equipo22.ipynb), donde se creó la columna `has_bar` derivada de `Bars`.\n",
    "\n",
    "En cuanto a la carga de imágenes, este conjunto de datos consiste en las imágenes de galaxias previamente procesadas en formato PNG. El preprocesamiento consiste, principalmente, en la sustracción de las bandas G y R para enfatizar las estructuras de barras. Las imágenes resultantes tienen dimensiones de 400x400 píxeles y están en escala de grises. Estas imágenes son cargadas utilizando la librería PIL y convertidas a tensores.\n",
    "\n",
    "El script de preprocesamiento puede ser consultado en este enlace: [bargal/commands/preprocess.py](https://github.com/ludanortmun/itesm-mna-barred-galaxies/blob/297f69b278ea6bc5099ef23a0d539602995bc55e/bargal/commands/preprocess.py)\n",
    "\n",
    "El conjunto de imágenes pre procesadas puede descargarse con el siguiente enlace: [dataset.processed.GRLogDiff](https://tecmx-my.sharepoint.com/:u:/g/personal/a01795197_tec_mx/EexaLnqaLLdCt1JNxLib8VYBeOHJo95vuOr-Pfxv-55Iww?e=0gfeuq)\n"
   ],
   "id": "aacb0a3cc0f666c1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T05:58:05.686123Z",
     "start_time": "2025-05-15T05:58:05.673354Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GalaxiesDataset(Dataset):\n",
    "    def __init__(self, galaxies_df: pd.DataFrame, img_dir: str):\n",
    "        self.labels = []\n",
    "        self.images = []\n",
    "\n",
    "        for i in range(len(galaxies_df)):\n",
    "            label = 1 if galaxies_df.iloc[i]['Bars'] != 0 else 0\n",
    "            galaxy_name = galaxies_df.iloc[i]['name']\n",
    "            img = Image.open(f\"{img_dir}/{galaxy_name}.png\")\n",
    "\n",
    "            self.labels.append(torch.tensor(label).to(device).float())\n",
    "            self.images.append(transforms.ToTensor()(img).to(device))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.images[idx], self.labels[idx]"
   ],
   "id": "4b5dc98dcd9ba6bc",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T05:58:07.317595Z",
     "start_time": "2025-05-15T05:58:06.827952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n = 32\n",
    "processed_images_path = '../data/processed'\n",
    "\n",
    "train_data = GalaxiesDataset(train_df, processed_images_path)\n",
    "train_loader = DataLoader(train_data, batch_size=n, shuffle=True)\n",
    "train_N = len(train_loader.dataset)\n",
    "\n",
    "valid_data = GalaxiesDataset(valid_df, processed_images_path)\n",
    "valid_loader = DataLoader(valid_data, batch_size=n)\n",
    "valid_N = len(valid_loader.dataset)"
   ],
   "id": "30ccf95a090ad809",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Definiendo el modelo",
   "id": "c204fa8ca4c12f96"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Debido a que estamos trabajando con imágenes, utilizaremos una red neuronal convolucional (CNN) como modelo base. La arquitectura de la red es la siguiente:",
   "id": "da2467289a9b28a8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T06:05:11.850256Z",
     "start_time": "2025-05-15T06:05:11.537440Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# TODO: define the model architecture\n",
    "\n",
    "model = nn.Sequential(\n",
    "    # First conv layer\n",
    "    nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),  # 32 x 400 x 400\n",
    "    nn.BatchNorm2d(25),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2, stride=2), # 32 x 200 x 200\n",
    "\n",
    "    ## Flattening\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(400*400, 512),\n",
    "    nn.Dropout(.3),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, 2)\n",
    ")"
   ],
   "id": "ed3b52a96da0ac0f",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T06:05:14.454581Z",
     "start_time": "2025-05-15T06:05:13.456171Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = torch.compile(model.to(device))\n",
    "model"
   ],
   "id": "c4ff2f951be42f25",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OptimizedModule(\n",
       "  (_orig_mod): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Flatten(start_dim=1, end_dim=-1)\n",
       "    (5): Linear(in_features=160000, out_features=512, bias=True)\n",
       "    (6): Dropout(p=0.3, inplace=False)\n",
       "    (7): ReLU()\n",
       "    (8): Linear(in_features=512, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Función de pérdida y optimizador\n",
    "\n",
    "Debido a que estamos trabajando con un problema de clasificación binaria, utilizaremos la función de pérdida `BCEWithLogitsLoss`. El optimizador a utilizar es Adam."
   ],
   "id": "7986c1f3e4b1418b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T06:09:25.447032Z",
     "start_time": "2025-05-15T06:09:25.431632Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loss_function = nn.BCEWithLogitsLoss()\n",
    "optimizer = Adam(model.parameters())\n",
    "my_model = model.to(device)"
   ],
   "id": "f4eff48e997b3f8e",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Entrenamiento",
   "id": "da8deb17900a2345"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Definiendo la función de entrenamiento",
   "id": "fd133f03e7b51a0d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_batch_accuracy(output, y, N):\n",
    "    zero_tensor = torch.tensor([0]).to(device)\n",
    "    pred = torch.gt(output, zero_tensor)\n",
    "    correct = pred.eq(y.view_as(pred)).sum().item()\n",
    "    return correct / N"
   ],
   "id": "b034f47b9836c7cb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def train():\n",
    "    loss = 0\n",
    "    accuracy = 0\n",
    "\n",
    "    model.train()\n",
    "    for x, y in train_loader:\n",
    "        output = model(x)\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss = loss_function(output, y)\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss += batch_loss.item()\n",
    "        accuracy += get_batch_accuracy(output, y, train_N)\n",
    "    print(f'Train - Loss: {loss:.4f} Accuracy: {accuracy:.4f}')"
   ],
   "id": "b94362a1333e42b6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def validate():\n",
    "    loss = 0\n",
    "    accuracy = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in valid_loader:\n",
    "            output = model(x)\n",
    "\n",
    "            loss += loss_function(output, y).item()\n",
    "            accuracy += get_batch_accuracy(output, y, valid_N)\n",
    "    print(f'Valid - Loss: {loss:.4f} Accuracy: {accuracy:.4f}')"
   ],
   "id": "2795ba41d0f55b2a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Ejecución del entrenamiento",
   "id": "560728de38354e39"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "epochs = 20\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print('Epoch: {}'.format(epoch))\n",
    "    train()\n",
    "    validate()"
   ],
   "id": "1d67a8475287287"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Guardando el modelo",
   "id": "1a8d8e28e2cc178"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model_path = '../models/model.pth'\n",
    "torch.save(model.state_dict(), model_path)"
   ],
   "id": "58e18d1f00f1df48"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Evaluación del modelo",
   "id": "ca41fcf5cf7413e3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Una vez entrenada la red neuronal, procedemos a evaluar su desempeño en el conjunto de prueba.",
   "id": "f0f5452ad751c2a0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# TODO: Using the train dataset, compute classification report, confusion matrix, etc.",
   "id": "450f94b461ec6a57"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
